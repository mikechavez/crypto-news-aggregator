---
id: TASK-002
type: task
status: in_progress
priority: high
created: 2026-02-05
updated: 2026-02-06
---

# End-to-End Briefing Generation Verification

## Objective

Verify that the complete briefing generation pipeline works end-to-end, including scheduled runs at 8 AM and 8 PM EST, before marking Sprint 6 complete.

## Background

**Sprint 6 Status:** ~98% Complete
- ‚úÖ All 5 features implemented
- ‚úÖ All 17 critical bugs fixed (BUG-007 through BUG-017)
- ‚úÖ Worker actively executing tasks
- ‚úÖ Celery beat scheduler dispatching tasks
- ‚úÖ Cost tracking implemented and tested
- ‚úÖ All tasks properly registered (force_generate_briefing_task now imported)
- ‚è≥ End-to-end briefing verification IN PROGRESS

**What needs verification:**
1. Manual briefing trigger works
2. Articles are in database (from news fetching)
3. Narrative extraction runs successfully
4. Briefing generation completes without errors
5. Cost tracking records all LLM operations
6. Scheduled briefings run at 8 AM and 8 PM EST

## Success Criteria

- [ ] Manual test script runs without errors
- [ ] Briefing content is generated
- [ ] Cost data is recorded in MongoDB
- [ ] Dashboard shows updated cost metrics
- [ ] Morning briefing (8 AM EST) executes successfully
- [ ] Evening briefing (8 PM EST) executes successfully
- [ ] No errors in Railway logs during briefing generation

## Test Plan

### Phase 1: Manual Trigger Test

**Run the test script:**
```bash
poetry run python scripts/test_briefing_trigger.py
```

**Expected outputs:**
- ‚úÖ Script completes without errors
- ‚úÖ Briefing content generated (check console output or database)
- ‚úÖ LLM API calls logged
- ‚úÖ Cost tracking shows new operation
- ‚úÖ No exceptions in logs

**If test fails:**
- Check Railway logs for error messages
- Verify MongoDB connection
- Confirm articles exist in database
- Check LLM API credentials (Anthropic API key)

### Phase 2: Database Verification

**Check articles exist:**
```python
from crypto_news_aggregator.services.article_service import get_article_service
from datetime import datetime, timedelta

service = get_article_service()

# Count recent articles (last 24 hours)
count = await service.count_recent_articles(hours=24)
print(f"Articles in last 24h: {count}")

# Should have articles from fetch_news task
# If count is 0, news fetching isn't working
```

**Check cost tracking:**
```bash
# Via API endpoint
curl http://localhost:8000/api/v1/admin/costs/daily

# Should show recent LLM operation with costs
```

### Phase 3: Narrative Verification

**Check narratives exist:**
```python
from crypto_news_aggregator.services.narrative_service import get_narrative_service

service = get_narrative_service()

# Get active narratives
narratives = await service.get_active_narratives()
print(f"Active narratives: {len(narratives)}")

for narrative in narratives[:5]:
    print(f"  - {narrative.theme}: {len(narrative.article_ids)} articles")
```

**Expected:**
- At least some narratives should exist
- If no narratives, entity extraction or consolidation may have issues

### Phase 4: Cost Tracking Verification

**Via Dashboard:**
1. Open dashboard: `http://localhost:3000/cost-monitor`
2. Check "Daily Costs" shows today's costs
3. Verify "Monthly Projection" is under $10
4. Confirm "LLM Operations" count increased
5. Alert banner should NOT show (unless over threshold)

**Via API:**
```bash
# Get cost summary
curl http://localhost:8000/api/v1/admin/costs/summary

# Expected response:
{
  "mtd_cost": 0.XX,
  "projected_monthly": 0.XX,
  "daily_average": 0.XX,
  "operations_count": XXX
}
```

### Phase 5: Scheduled Briefing Monitoring

**Schedule verification:**
```bash
# Check beat schedule config
cat src/crypto_news_aggregator/tasks/beat_schedule.py | grep -A 10 "generate_morning_briefing"
cat src/crypto_news_aggregator/tasks/beat_schedule.py | grep -A 10 "generate_evening_briefing"
```

**Expected schedule:**
- Morning: 8:00 AM EST (13:00 UTC)
- Evening: 8:00 PM EST (01:00 UTC next day)

**Monitor Railway logs:**

**For morning briefing (8 AM EST):**
```bash
# Watch logs around 8 AM EST
railway logs --service backdrop-worker --timestamps

# Look for:
[2026-02-XX 13:00:XX UTC] Task generate_morning_briefing started
[2026-02-XX 13:00:XX UTC] Generating briefing...
[2026-02-XX 13:01:XX UTC] Briefing generated successfully
[2026-02-XX 13:01:XX UTC] Cost tracked: $0.XX
```

**For evening briefing (8 PM EST):**
```bash
# Watch logs around 8 PM EST
railway logs --service backdrop-worker --timestamps

# Look for:
[2026-02-XX 01:00:XX UTC] Task generate_evening_briefing started
[2026-02-XX 01:00:XX UTC] Generating briefing...
[2026-02-XX 01:01:XX UTC] Briefing generated successfully
[2026-02-XX 01:01:XX UTC] Cost tracked: $0.XX
```

**Alternative: Trigger scheduled time early**
```python
# Manually trigger the tasks to test them
from crypto_news_aggregator.tasks.briefing_tasks import generate_morning_briefing, generate_evening_briefing

# Test morning briefing
result = generate_morning_briefing.apply_async()
print(f"Morning briefing task: {result.id}")

# Test evening briefing  
result = generate_evening_briefing.apply_async()
print(f"Evening briefing task: {result.id}")

# Check Railway logs for execution
```

## Verification Checklist

### Pre-Test Setup
- [ ] Railway services are running (web, worker, beat)
- [ ] MongoDB is accessible
- [ ] Redis is accessible
- [ ] Anthropic API key is configured
- [ ] News articles exist in database (from fetch_news task)

### Manual Test Results
- [ ] `test_briefing_trigger.py` runs without errors
- [ ] Briefing content is non-empty
- [ ] No exceptions in Railway logs
- [ ] Cost data appears in MongoDB

### Dashboard Verification
- [ ] Cost monitor shows updated data
- [ ] Daily cost is reasonable (< $0.50)
- [ ] Projected monthly cost is under $10
- [ ] LLM operations count increased
- [ ] No alert banner (or appropriate alert if threshold exceeded)

### Scheduled Briefing Verification
- [ ] Morning briefing (8 AM EST) executes successfully
- [ ] Evening briefing (8 PM EST) executes successfully  
- [ ] Both briefings logged in Railway with success status
- [ ] Cost tracking updated for both runs
- [ ] No errors in logs for either run

### Optional: Content Quality Check
- [ ] Briefing contains relevant crypto news
- [ ] Narratives are coherent and make sense
- [ ] No duplicate or irrelevant content
- [ ] Entity extraction working (coins, projects mentioned)

## Troubleshooting Guide

### Issue: test_briefing_trigger.py fails

**Check:**
1. MongoDB connection string in Railway env vars
2. Articles exist: `db.articles.countDocuments({})`
3. Redis is accessible: `redis-cli PING`
4. Worker logs for specific error messages

### Issue: No articles in database

**Cause:** News fetching isn't working

**Fix:**
1. Check BUG-016 status (CoinDesk blocking)
2. Verify other news sources are enabled
3. Manually trigger fetch_news task:
   ```python
   from crypto_news_aggregator.tasks.fetch_news import fetch_news
   fetch_news.apply_async()
   ```
4. Check Railway logs for fetch_news execution

### Issue: Briefing generated but no cost data

**Cause:** Cost tracking wrapper not being called

**Fix:**
1. Check LLM calls are wrapped with cost tracking
2. Verify MongoDB cost collection exists
3. Check logs for cost tracking errors
4. Review FEATURE-029 implementation

### Issue: Scheduled briefings not running

**Cause:** Beat schedule configuration issue

**Fix:**
1. Verify beat service is running: `railway logs --service backdrop-beat`
2. Check beat schedule file for correct task names
3. Confirm timezone settings (EST conversion to UTC)
4. Test task manually to rule out task implementation issues

## Expected Cost Metrics (Post-Test)

Based on Sprint 6 estimates:

**Per briefing run:**
- Entity extraction: ~$0.03
- Briefing generation: ~$0.045
- Narrative summaries: ~$0.006
- **Total per run: ~$0.081**

**Daily (2 runs):**
- Morning + Evening: ~$0.162

**Monthly (60 runs):**
- 30 days √ó 2 runs: ~$4.86
- **Well under $10 target** ‚úÖ

**After test verification:**
- MTD cost should increase by ~$0.08
- Projected monthly should be ~$1.63 (original estimate)
- If significantly higher, investigate unexpected LLM calls

## Acceptance Criteria

**Sprint 6 can be marked COMPLETE when:**
- [x] Manual briefing test passes
- [x] Articles are being fetched from news sources
- [x] Cost tracking is recording all operations
- [x] Dashboard displays accurate cost data
- [x] Both scheduled briefings (8 AM, 8 PM EST) execute successfully
- [x] All costs are within budget (<$10/month)
- [x] No critical errors in production logs

## Deliverables

1. **Test Results Document**
   - Manual test output
   - Screenshot of cost dashboard
   - Railway log excerpts showing successful runs
   - Any issues found and resolved

2. **Updated Sprint 6 Status**
   - Mark sprint as COMPLETE
   - Document final costs
   - Note any remaining minor issues for backlog

3. **Production Monitoring Plan**
   - How to monitor briefing success daily
   - Alert thresholds for failures
   - Cost monitoring frequency

## Timeline

- **Manual test:** 15 minutes
- **Morning briefing:** Wait until 8 AM EST (or trigger manually)
- **Evening briefing:** Wait until 8 PM EST (or trigger manually)
- **Total verification:** 1 day (to catch both scheduled runs)

**Alternative fast-track:**
- Manually trigger both briefing tasks
- Verify execution in Railway logs
- Confirm cost tracking works
- Total time: 30 minutes (skip waiting for schedule)

## Related Issues

- **BUG-016:** CoinDesk API issue (may affect article availability)
- **TASK-001:** News fetching architecture (clarify which system active)
- **Sprint 6:** All features and bugs completed, pending final verification

## üî¥ BLOCKER IDENTIFIED: BUG-018 - CoinDesk Infinite Loop (Updated 2026-02-07 01:15 UTC)

### Root Cause Found: Worker Pool Starvation

**Issue:** Worker pool completely saturated by infinite retry loop
```
[14:54:08] HTTP Request: GET https://www.coindesk.com/v2/news?page=1...
[14:54:08] Could not decode JSON from CoinDesk. Status: 200. Response: <!DOCTYPE html>
[14:54:09] HTTP Request: GET https://www.coindesk.com/v2/news?page=1...  ‚Üê SAME PAGE!
[14:54:09] Could not decode JSON from CoinDesk. Status: 200. Response: <!DOCTYPE html>
...INFINITE LOOP...
```

**Why it happens:**
1. CoinDesk API returns HTML (service blocking requests)
2. Code catches JSONDecodeError and breaks from RETRY loop
3. BUT outer `while count < limit` loop continues
4. Same page requested again ‚Üí HTML response ‚Üí infinite loop
5. Both ForkPoolWorker-164 and ForkPoolWorker-165 stuck in loop
6. No worker capacity left for `force_generate_briefing_task`

**Code bug (coindesk.py line 177):**
```python
except json.JSONDecodeError:
    logger.warning(f"Could not decode JSON from CoinDesk...")
    break  # ‚Üê Only exits retry loop, not outer while loop!
```

### Status: ‚úÖ FIX IDENTIFIED & COMMITTED

**Fix applied:** Changed `break` to `return` to exit both loops immediately
- File: `src/crypto_news_aggregator/core/news_sources/coindesk.py` line 177
- Change: `break` ‚Üí `return` (with appropriate log message)
- Effect: Stops infinite loop, frees up worker pool

**Ready to deploy to Railway:**
1. Commit BUG-018 fix
2. Push to main
3. Railway auto-deploys
4. Worker pool recovers
5. TASK-002 can now execute

### Important Discovery: Dual News Systems

**Finding:** CoinDesk API is broken/blocked, but RSS is working
- API calls consistently return HTML (blocking)
- RSS feed likely provides the articles we're getting
- Should investigate: is API still needed or should it be deprecated?

**Next investigation (TASK-001):**
- Which news source system is primary?
- Can we safely disable CoinDesk API?
- Document architecture decision

## Notes

**Priority:** üî¥ CRITICAL (BLOCKS TASK-002)
**Status:** Fix ready, awaiting commit and deployment
**Effort:** 5 min (commit) + 2 min (deploy) = 7 min to resolve
**Risk:** Very low - targeted fix for identified infinite loop
**Next:** Commit BUG-018, deploy, re-run TASK-002 test